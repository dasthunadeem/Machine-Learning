#Importing Data Set:
a_original=read.delim('Restaurant_Reviews.tsv',quote = '',stringsAsFactors = FALSE)

#Cleaning the Data Set:
library(tm)             # Library used for cleaning Processco
corpous=VCorpus(VectorSource(a_original$Review))
corpous=tm_map(corpous,content_transformer(tolower)) # lowercase
#as.character(Corpus[[1]])
corpous=tm_map(corpous,removeNumbers) #removes number
corpous=tm_map(corpous,removePunctuation)  # removes punctuation
corpous=tm_map(corpous,removeWords,stopwords()) # removes stopwords
corpous=tm_map(corpous,stemDocument)  # converting to Stemwords
corpous=tm_map(corpous,stripWhitespace) # removing extra space

#Creating Bag of Words Model:
"""
Bag of Words Model Consist all the Unique words and converting each word
to a coloumn, 
each review will be having many columns of Unique word 
In short,will be the input for Sparse matrix 
"""
dtm=DocumentTermMatrix(corpous) 
dtm=removeSparseTerms(dtm,0.999)

#Fitting the data to Classification Module:

#converting Matrix 'dtm' into data Frame
a=as.data.frame(as.matrix(dtm))  
#since input of classfication Module is a data frame with 'independent' & 'dependent' variable
a$Liked=a_original$Liked

#Random Forest Model:
#since Naive bays will creat an error to predict the Prob bet 0 and 1
a$Liked=factor(a$Liked,levels = c(0,1)) 

#Splitting the Data set to Training and Testing Data:
library(caTools)
set.seed(123)
split=sample.split(a$Liked,SplitRatio=0.8)
training_set=subset(a,split==TRUE)
testing_set=subset(a,split==FALSE)

#Fitting the data to Random Forest Module:
library(randomForest)
classifier=randomForest(x=training_set[,-692],
                        y=training_set$Liked,
                        ntree=10)

#Finding the Probability of each data and then predicting 0 or 1 :
#Predicting the test set:
y_pred=predict(classifier,newdata = testing_set[,-692])

#Confusion Metrix to evaluate the prediction:
met=table(testing_set$Liked,y_pred)
Accuracy=(sum(diag(met))/sum(met))*100
